**# LIPS-MOVEMENT-DETECTION-model-app**
Our junior design project CSE299 Lip_Movement_Detection uses computer vision and deep learning to understand speech or non-verbal communication.

Lip movement detection is a computer vision technique that finds and tracks the movement of the lips in a video or image. This technology has a wide range of
applications, including speech recognition, lip reading, and facial expression recognition. The goals of this project are to: Develop a 
LIPS-MOVEMENT-DETECTION-model-app that can detect and track lip movement in real time. Train a deep learning model for lip movement detection.
Evaluate the performance of the app on a variety of datasets. The results of this project will be a LIPS-MOVEMENT-DETECTION-model-app that can be used to 
detect and track lip movement in real time. The app will be a valuable tool for researchers and developers working on speech recognition, lip reading, and 
facial expression recognition. 

Dataset drive link- [https://drive.google.com/file/d/1RIqWkZuvAr4KlpQOt7IODcoc_YKJEJJJ/view?usp=sharing](https://drive.google.com/file/d/1RIqWkZuvAr4KlpQOt7IODcoc_YKJEJJJ/view?usp=sharing)


Model zip folder drive link -[https://drive.google.com/file/d/15b5s4r0obQ1-bIXb7Q_5eQUx61zxQ0oB/view?usp=sharing](https://drive.google.com/file/d/15b5s4r0obQ1-bIXb7Q_5eQUx61zxQ0oB/view?usp=sharing)
![Screenshot 2023-06-18 220645.PNG](https://github.com/Tas890/LIPS-MOVEMENT-DETECTION-model-app/assets/104415687/b12dc505-b267-41e1-9d13-1d2bfa1033ae)
